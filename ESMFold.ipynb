{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkywalkerLuke/DiffuSeq/blob/main/ESMFold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ESMFold**\n",
        "for more details see: [Github](https://github.com/facebookresearch/esm/tree/main/esm), [Preprint](https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1)\n",
        "\n",
        "#### **Tips and Instructions**\n",
        "- click the little ▶ play icon to the left of each cell below.\n",
        "- use \"/\" to specify chainbreaks, (eg. sequence=\"AAA/AAA\")\n",
        "- for homo-oligomeric predictions, set copies > 1\n",
        "- See [experimental notebook](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/ESMFold_advanced.ipynb) for more advanced options (like sampling).\n",
        "\n",
        "#### **Colab Limitations**\n",
        "- For short monomeric proteins under the length 400, consider using [ESMFold API](https://esmatlas.com/resources?action=fold) (no need for GPU, super fast!)\n",
        "- On Tesla T4 (typical free colab GPU), max total length ~ 900"
      ],
      "metadata": {
        "id": "POQBeXf2Xoxo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "boFQEwsNQ4Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8949751c-b29c-48a3-f6f9-d861526b1bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "installing libs...\n",
            "installing openfold...\n",
            "installing esmfold...\n",
            "CPU times: user 8.74 ms, sys: 6.39 ms, total: 15.1 ms\n",
            "Wall time: 3min 20s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "#@title install\n",
        "#@markdown install ESMFold, OpenFold and download Params (~2min 30s)\n",
        "version = \"1\" # @param [\"0\", \"1\"]\n",
        "model_name = \"esmfold_v0.model\" if version == \"0\" else \"esmfold.model\"\n",
        "import os, time\n",
        "if not os.path.isfile(model_name):\n",
        "  # download esmfold params\n",
        "  os.system(\"apt-get install aria2 -qq\")\n",
        "  os.system(f\"aria2c -q -x 16 https://colabfold.steineggerlab.workers.dev/esm/{model_name} &\")\n",
        "\n",
        "  if not os.path.isfile(\"finished_install\"):\n",
        "    # install libs\n",
        "    print(\"installing libs...\")\n",
        "    os.system(\"pip install -q omegaconf pytorch_lightning biopython ml_collections einops py3Dmol modelcif\")\n",
        "    os.system(\"pip install -q git+https://github.com/NVIDIA/dllogger.git\")\n",
        "\n",
        "    print(\"installing openfold...\")\n",
        "    # install openfold\n",
        "    os.system(f\"pip install -q git+https://github.com/sokrypton/openfold.git\")\n",
        "\n",
        "    print(\"installing esmfold...\")\n",
        "    # install esmfold\n",
        "    os.system(f\"pip install -q git+https://github.com/sokrypton/esm.git\")\n",
        "    os.system(\"touch finished_install\")\n",
        "\n",
        "  # wait for Params to finish downloading...\n",
        "  while not os.path.isfile(model_name):\n",
        "    time.sleep(5)\n",
        "  if os.path.isfile(f\"{model_name}.aria2\"):\n",
        "    print(\"downloading params...\")\n",
        "  while os.path.isfile(f\"{model_name}.aria2\"):\n",
        "    time.sleep(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##run **ESMFold**\n",
        "%%time\n",
        "from string import ascii_uppercase, ascii_lowercase\n",
        "import hashlib, re, os\n",
        "import numpy as np\n",
        "import torch\n",
        "from jax.tree_util import tree_map\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import softmax\n",
        "import gc\n",
        "\n",
        "def parse_output(output):\n",
        "  pae = (output[\"aligned_confidence_probs\"][0] * np.arange(64)).mean(-1) * 31\n",
        "  plddt = output[\"plddt\"][0,:,1]\n",
        "\n",
        "  bins = np.append(0,np.linspace(2.3125,21.6875,63))\n",
        "  sm_contacts = softmax(output[\"distogram_logits\"],-1)[0]\n",
        "  sm_contacts = sm_contacts[...,bins<8].sum(-1)\n",
        "  xyz = output[\"positions\"][-1,0,:,1]\n",
        "  mask = output[\"atom37_atom_exists\"][0,:,1] == 1\n",
        "  o = {\"pae\":pae[mask,:][:,mask],\n",
        "       \"plddt\":plddt[mask],\n",
        "       \"sm_contacts\":sm_contacts[mask,:][:,mask],\n",
        "       \"xyz\":xyz[mask]}\n",
        "  return o\n",
        "\n",
        "def get_hash(x): return hashlib.sha1(x.encode()).hexdigest()\n",
        "alphabet_list = list(ascii_uppercase+ascii_lowercase)\n",
        "\n",
        "jobname = \"test\" #@param {type:\"string\"}\n",
        "jobname = re.sub(r'\\W+', '', jobname)[:50]\n",
        "\n",
        "sequence = \"GWSTELEKHREELKEFLKKEGITNVEIRIDNGRLEVRVEGGTERLKRFLEELRQKLEKKGYTVDIKIE\" #@param {type:\"string\"}\n",
        "sequence = re.sub(\"[^A-Z:]\", \"\", sequence.replace(\"/\",\":\").upper())\n",
        "sequence = re.sub(\":+\",\":\",sequence)\n",
        "sequence = re.sub(\"^[:]+\",\"\",sequence)\n",
        "sequence = re.sub(\"[:]+$\",\"\",sequence)\n",
        "copies = 1 #@param {type:\"integer\"}\n",
        "if copies == \"\" or copies <= 0: copies = 1\n",
        "sequence = \":\".join([sequence] * copies)\n",
        "num_recycles = 3 #@param [\"0\", \"1\", \"2\", \"3\", \"6\", \"12\", \"24\"] {type:\"raw\"}\n",
        "chain_linker = 25\n",
        "\n",
        "ID = jobname+\"_\"+get_hash(sequence)[:5]\n",
        "seqs = sequence.split(\":\")\n",
        "lengths = [len(s) for s in seqs]\n",
        "length = sum(lengths)\n",
        "print(\"length\",length)\n",
        "\n",
        "u_seqs = list(set(seqs))\n",
        "if len(seqs) == 1: mode = \"mono\"\n",
        "elif len(u_seqs) == 1: mode = \"homo\"\n",
        "else: mode = \"hetero\"\n",
        "\n",
        "if \"model\" not in dir() or model_name != model_name_:\n",
        "  if \"model\" in dir():\n",
        "    # delete old model from memory\n",
        "    del model\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "  model = torch.load(model_name, weights_only=False)\n",
        "  model.eval().cuda().requires_grad_(False)\n",
        "  model_name_ = model_name\n",
        "\n",
        "# optimized for Tesla T4\n",
        "if length > 700:\n",
        "  model.set_chunk_size(64)\n",
        "else:\n",
        "  model.set_chunk_size(128)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "output = model.infer(sequence,\n",
        "                     num_recycles=num_recycles,\n",
        "                     chain_linker=\"X\"*chain_linker,\n",
        "                     residue_index_offset=512)\n",
        "\n",
        "pdb_str = model.output_to_pdb(output)[0]\n",
        "output = tree_map(lambda x: x.cpu().numpy(), output)\n",
        "ptm = output[\"ptm\"][0]\n",
        "plddt = output[\"plddt\"][0,...,1].mean()\n",
        "O = parse_output(output)\n",
        "print(f'ptm: {ptm:.3f} plddt: {plddt:.3f}')\n",
        "os.system(f\"mkdir -p {ID}\")\n",
        "prefix = f\"{ID}/ptm{ptm:.3f}_r{num_recycles}_default\"\n",
        "np.savetxt(f\"{prefix}.pae.txt\",O[\"pae\"],\"%.3f\")\n",
        "with open(f\"{prefix}.pdb\",\"w\") as out:\n",
        "  out.write(pdb_str)"
      ],
      "metadata": {
        "id": "CcyNpAvhTX6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe3f7c5-92f7-41e7-ed96-3e4688c5dc23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length 68\n",
            "ptm: 0.817 plddt: 90.519\n",
            "CPU times: user 12.2 s, sys: 8.07 s, total: 20.2 s\n",
            "Wall time: 51.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyIdXD9T-wEu",
        "outputId": "b0f544f8-d2f7-44b0-a0de-fe2d8f20970e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os, re, glob, hashlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from jax.tree_util import tree_map\n",
        "from scipy.special import softmax\n",
        "import torch\n",
        "\n",
        "INPUT_DIR  = \"/content/drive/MyDrive/B-cell/data\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/B-cell/esmfold_outputs_min\"\n",
        "SEQ_COL = \"Epitope.1\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def parse_output(output):\n",
        "  pae = (output[\"aligned_confidence_probs\"][0] * np.arange(64)).mean(-1) * 31\n",
        "  plddt = output[\"plddt\"][0,:,1]\n",
        "  bins = np.append(0,np.linspace(2.3125,21.6875,63))\n",
        "  sm_contacts = softmax(output[\"distogram_logits\"],-1)[0]\n",
        "  sm_contacts = sm_contacts[...,bins<8].sum(-1)\n",
        "  xyz = output[\"positions\"][-1,0,:,1]\n",
        "  mask = output[\"atom37_atom_exists\"][0,:,1] == 1\n",
        "  o = {\"pae\":pae[mask,:][:,mask],\n",
        "       \"plddt\":plddt[mask]}\n",
        "  return o\n",
        "\n",
        "def clean(seq):\n",
        "  seq = re.sub(\"[^A-Z:]\", \"\", str(seq).replace(\"/\",\":\").upper())\n",
        "  seq = re.sub(\":+\",\":\",seq)\n",
        "  seq = re.sub(\"^[:]+\",\"\",seq)\n",
        "  seq = re.sub(\"[:]+$\",\"\",seq)\n",
        "  return seq\n",
        "\n",
        "def short_hash(x):\n",
        "  return hashlib.sha1(x.encode()).hexdigest()[:8]\n",
        "\n",
        "# 需要你自己保证：model 已经按你原方法 load 好了\n",
        "# model = torch.load(model_name, weights_only=False)\n",
        "# model.eval().cuda().requires_grad_(False)\n",
        "\n",
        "def run_one_sequence(sequence, out_prefix, num_recycles=3, chain_linker=25):\n",
        "  seqs = sequence.split(\":\")\n",
        "  length = sum(len(s) for s in seqs)\n",
        "  if length > 700:\n",
        "    model.set_chunk_size(64)\n",
        "  else:\n",
        "    model.set_chunk_size(128)\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "  output = model.infer(sequence,\n",
        "                       num_recycles=num_recycles,\n",
        "                       chain_linker=\"X\"*chain_linker,\n",
        "                       residue_index_offset=512)\n",
        "  pdb_str = model.output_to_pdb(output)[0]\n",
        "  output = tree_map(lambda x: x.cpu().numpy(), output)\n",
        "  ptm = float(output[\"ptm\"][0])\n",
        "  plddt = float(output[\"plddt\"][0,...,1].mean())\n",
        "  O = parse_output(output)\n",
        "\n",
        "  with open(out_prefix + \".pdb\",\"w\") as f:\n",
        "    f.write(pdb_str)\n",
        "  np.savetxt(out_prefix + \".pae.txt\", O[\"pae\"], \"%.3f\")\n",
        "\n",
        "  return ptm, plddt\n",
        "\n",
        "# 批量跑 fold/test\n",
        "files = sorted(glob.glob(os.path.join(INPUT_DIR, \"dataset_fold*.tsv\")))\n",
        "testf = os.path.join(INPUT_DIR, \"dataset_test.tsv\")\n",
        "if os.path.exists(testf):\n",
        "  files.append(testf)\n",
        "\n",
        "for fp in files:\n",
        "  name = os.path.splitext(os.path.basename(fp))[0]\n",
        "  df = pd.read_csv(fp, sep=\"\\t\")\n",
        "  seqs = [clean(s) for s in df[SEQ_COL].tolist()]\n",
        "  uniq = sorted(set(seqs))\n",
        "\n",
        "  out_dir = os.path.join(OUTPUT_DIR, name)\n",
        "  os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "  for s in tqdm(uniq, desc=name):\n",
        "    out_prefix = os.path.join(out_dir, f\"{s}_{short_hash(s)}\")\n",
        "    if os.path.exists(out_prefix + \".pdb\"):\n",
        "      continue\n",
        "    run_one_sequence(s, out_prefix, num_recycles=3, chain_linker=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjRhug0V-sn6",
        "outputId": "ace38831-ad90-4fde-a7e1-24dd6614fc55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "dataset_fold1:  12%|█▏        | 2942/24888 [1:16:28<9:24:14,  1.54s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, time\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ======================\n",
        "# 配置\n",
        "# ======================\n",
        "PDB_ROOT   = \"/content/drive/MyDrive/B-cell/esmfold_outputs_min\"\n",
        "GRAPH_ROOT = \"/content/drive/MyDrive/B-cell/esmfold_contacts_ca8\"\n",
        "\n",
        "THR_A = 8.0\n",
        "CHAIN_ID = \"A\"          # 不确定链名就设 None（读所有链的CA）\n",
        "MIN_SEQ_SEP = None      # 例如 3 可去掉 |i-j|<3 的边；不需要就 None\n",
        "OVERWRITE = False\n",
        "SAVE_EDGE_INDEX = True\n",
        "\n",
        "# ======================\n",
        "# 基础函数：读取/计算/保存\n",
        "# ======================\n",
        "def ensure_dir(p):\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def read_ca_from_pdb_path(pdb_path, chain_id=None):\n",
        "    \"\"\"逐行扫描PDB，仅提取CA坐标。\"\"\"\n",
        "    res_ids = []\n",
        "    xyz = []\n",
        "    with open(pdb_path, \"r\") as f:\n",
        "        for line in f:\n",
        "            if not (line.startswith(\"ATOM\") or line.startswith(\"HETATM\")):\n",
        "                continue\n",
        "            if line[12:16].strip() != \"CA\":\n",
        "                continue\n",
        "\n",
        "            ch = line[21].strip()\n",
        "            if chain_id is not None and ch != chain_id:\n",
        "                continue\n",
        "\n",
        "            resseq = int(line[22:26])\n",
        "            icode = line[26].strip()\n",
        "            x = float(line[30:38]); y = float(line[38:46]); z = float(line[46:54])\n",
        "            res_ids.append((ch, resseq, icode))\n",
        "            xyz.append((x, y, z))\n",
        "\n",
        "    return res_ids, np.asarray(xyz, dtype=np.float32)\n",
        "\n",
        "def pairwise_distances(X):\n",
        "    diff = X[:, None, :] - X[None, :, :]\n",
        "    return np.sqrt(np.sum(diff * diff, axis=-1))\n",
        "\n",
        "def make_contact_adj_from_ca(ca_xyz, thr_A=8.0, remove_self=True, min_seq_sep=None):\n",
        "    D = pairwise_distances(ca_xyz)\n",
        "    A = (D < thr_A).astype(np.uint8)\n",
        "\n",
        "    if remove_self:\n",
        "        np.fill_diagonal(A, 0)\n",
        "\n",
        "    if min_seq_sep is not None and min_seq_sep > 0:\n",
        "        n = A.shape[0]\n",
        "        for i in range(n):\n",
        "            lo = max(0, i - (min_seq_sep - 1))\n",
        "            hi = min(n, i + (min_seq_sep - 1) + 1)\n",
        "            A[i, lo:hi] = 0\n",
        "\n",
        "    return A  # 你最终主要用A即可（更快更省）\n",
        "\n",
        "def adjacency_to_edge_index(A):\n",
        "    src, dst = np.where(A > 0)\n",
        "    return np.stack([src, dst], axis=0).astype(np.int64)  # (2,E)\n",
        "\n",
        "def mirror_out_path(pdb_path, pdb_root, graph_root, suffix):\n",
        "    \"\"\"\n",
        "    pdb_root/**/xxx.pdb  -> graph_root/**/xxx{suffix}\n",
        "    \"\"\"\n",
        "    rel = os.path.relpath(pdb_path, pdb_root)\n",
        "    rel_noext = os.path.splitext(rel)[0]\n",
        "    out_path = os.path.join(graph_root, rel_noext + suffix)\n",
        "    ensure_dir(os.path.dirname(out_path))\n",
        "    return out_path\n",
        "\n",
        "# ======================\n",
        "# 可见性强的主流程\n",
        "# ======================\n",
        "def run_all_verbose(\n",
        "    pdb_root,\n",
        "    graph_root,\n",
        "    thr_A=8.0,\n",
        "    chain_id=\"A\",\n",
        "    min_seq_sep=None,\n",
        "    overwrite=False,\n",
        "    save_edge_index=True,\n",
        "):\n",
        "    t_start = time.time()\n",
        "\n",
        "    print(\"========== 0) 配置 ==========\")\n",
        "    print(\"PDB_ROOT  :\", pdb_root)\n",
        "    print(\"GRAPH_ROOT:\", graph_root)\n",
        "    print(\"thr_A     :\", thr_A)\n",
        "    print(\"chain_id  :\", chain_id)\n",
        "    print(\"min_seq_sep:\", min_seq_sep)\n",
        "    print(\"overwrite :\", overwrite)\n",
        "    print(\"save_edge_index:\", save_edge_index)\n",
        "    print()\n",
        "\n",
        "    print(\"========== 1) 路径检查 ==========\")\n",
        "    print(\"PDB_ROOT exists?  \", os.path.exists(pdb_root))\n",
        "    if not os.path.exists(pdb_root):\n",
        "        raise FileNotFoundError(f\"PDB_ROOT not found: {pdb_root}\")\n",
        "    ensure_dir(graph_root)\n",
        "    print(\"GRAPH_ROOT exists?\", os.path.exists(graph_root))\n",
        "    print()\n",
        "\n",
        "    print(\"========== 2) 枚举 split 文件夹（PDB_ROOT 下的一级子目录） ==========\")\n",
        "    split_dirs = sorted([d for d in glob.glob(os.path.join(pdb_root, \"*\")) if os.path.isdir(d)])\n",
        "    print(\"split_dirs count:\", len(split_dirs))\n",
        "    if split_dirs:\n",
        "        print(\"split dir names :\", [os.path.basename(d) for d in split_dirs])\n",
        "    print()\n",
        "\n",
        "    # 统计每个 split 下 pdb 数量（一级） + 递归总数\n",
        "    print(\"========== 3) 统计文件数量 ==========\")\n",
        "    per_split_counts = []\n",
        "    total_pdb_one_level = 0\n",
        "    for sd in split_dirs:\n",
        "        c = len(glob.glob(os.path.join(sd, \"*.pdb\")))\n",
        "        per_split_counts.append((os.path.basename(sd), c))\n",
        "        total_pdb_one_level += c\n",
        "\n",
        "    print(\"PDB count (one-level per split):\")\n",
        "    for name, c in per_split_counts:\n",
        "        print(f\"  - {name}: {c}\")\n",
        "\n",
        "    # 递归统计（如果你的PDB不止一层目录，这个才是实际会处理到的）\n",
        "    pdb_files = sorted(glob.glob(os.path.join(pdb_root, \"**\", \"*.pdb\"), recursive=True))\n",
        "    print(\"PDB count (recursive under PDB_ROOT):\", len(pdb_files))\n",
        "    if len(pdb_files) == 0:\n",
        "        print(\"没有找到任何 .pdb 文件：请检查目录层级/扩展名。\")\n",
        "        return\n",
        "    print()\n",
        "\n",
        "    print(\"========== 4) 开始处理（按 split 分组） ==========\")\n",
        "    # 把pdb按 split 名分组（只按 PDB_ROOT 的第一层目录名归类）\n",
        "    groups = {}\n",
        "    for p in pdb_files:\n",
        "        rel = os.path.relpath(p, pdb_root)\n",
        "        split = rel.split(os.sep)[0]  # 第一段\n",
        "        groups.setdefault(split, []).append(p)\n",
        "\n",
        "    print(\"Will process splits:\")\n",
        "    for k in sorted(groups.keys()):\n",
        "        print(f\"  - {k}: {len(groups[k])} pdb\")\n",
        "    print()\n",
        "\n",
        "    # 总进度条\n",
        "    total = len(pdb_files)\n",
        "    pbar_total = tqdm(total=total, desc=\"TOTAL\", unit=\"pdb\")\n",
        "\n",
        "    # 统计\n",
        "    n_done = 0\n",
        "    n_skipped = 0\n",
        "    n_failed = 0\n",
        "    n_no_ca = 0\n",
        "\n",
        "    for split in sorted(groups.keys()):\n",
        "        files = sorted(groups[split])\n",
        "        pbar_split = tqdm(files, desc=f\"SPLIT {split}\", unit=\"pdb\", leave=False)\n",
        "\n",
        "        for pdb_path in pbar_split:\n",
        "            try:\n",
        "                out_adj  = mirror_out_path(pdb_path, pdb_root, graph_root, f\".ca{thr_A:.0f}.adj.npy\")\n",
        "                out_meta = mirror_out_path(pdb_path, pdb_root, graph_root, f\".ca{thr_A:.0f}.meta.npz\")\n",
        "                out_edge = mirror_out_path(pdb_path, pdb_root, graph_root, f\".ca{thr_A:.0f}.edge_index.npy\")\n",
        "\n",
        "                already = os.path.exists(out_adj) and os.path.exists(out_meta) and (\n",
        "                    (not save_edge_index) or os.path.exists(out_edge)\n",
        "                )\n",
        "                if (not overwrite) and already:\n",
        "                    n_skipped += 1\n",
        "                    continue\n",
        "\n",
        "                res_ids, ca_xyz = read_ca_from_pdb_path(pdb_path, chain_id=chain_id)\n",
        "                if ca_xyz.shape[0] == 0:\n",
        "                    n_no_ca += 1\n",
        "                    continue\n",
        "\n",
        "                A = make_contact_adj_from_ca(\n",
        "                    ca_xyz, thr_A=thr_A, remove_self=True, min_seq_sep=min_seq_sep\n",
        "                )\n",
        "                np.save(out_adj, A)\n",
        "\n",
        "                if save_edge_index:\n",
        "                    edge_index = adjacency_to_edge_index(A)\n",
        "                    np.save(out_edge, edge_index)\n",
        "\n",
        "                # 元信息：不打印文件名，但保存路径便于追溯\n",
        "                np.savez(\n",
        "                    out_meta,\n",
        "                    pdb_path=pdb_path,\n",
        "                    thr_A=float(thr_A),\n",
        "                    chain_id=\"\" if chain_id is None else chain_id,\n",
        "                    min_seq_sep=-1 if min_seq_sep is None else int(min_seq_sep),\n",
        "                    n_res=int(len(res_ids)),\n",
        "                    res_ids=np.array(res_ids, dtype=object),\n",
        "                )\n",
        "\n",
        "                n_done += 1\n",
        "\n",
        "            except Exception:\n",
        "                n_failed += 1\n",
        "                # 不打印具体文件名：这里仅记一次失败\n",
        "                # 如果你想排查，可把 traceback 打开\n",
        "                # import traceback; traceback.print_exc()\n",
        "            finally:\n",
        "                pbar_total.update(1)\n",
        "                # 在进度条上显示统计（不含文件名）\n",
        "                pbar_total.set_postfix({\n",
        "                    \"done\": n_done,\n",
        "                    \"skip\": n_skipped,\n",
        "                    \"noCA\": n_no_ca,\n",
        "                    \"fail\": n_failed,\n",
        "                })\n",
        "\n",
        "        pbar_split.close()\n",
        "\n",
        "    pbar_total.close()\n",
        "\n",
        "    print()\n",
        "    print(\"========== 5) 汇总 ==========\")\n",
        "    print(\"total pdb:\", total)\n",
        "    print(\"done     :\", n_done)\n",
        "    print(\"skipped  :\", n_skipped)\n",
        "    print(\"no CA    :\", n_no_ca)\n",
        "    print(\"failed   :\", n_failed)\n",
        "    print(\"elapsed(s):\", round(time.time() - t_start, 2))\n",
        "\n",
        "# 执行\n",
        "run_all_verbose(\n",
        "    pdb_root=PDB_ROOT,\n",
        "    graph_root=GRAPH_ROOT,\n",
        "    thr_A=THR_A,\n",
        "    chain_id=CHAIN_ID,\n",
        "    min_seq_sep=MIN_SEQ_SEP,\n",
        "    overwrite=OVERWRITE,\n",
        "    save_edge_index=SAVE_EDGE_INDEX,\n",
        ")"
      ],
      "metadata": {
        "id": "X-X49Vaw6kD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title display (optional) {run: \"auto\"}\n",
        "import py3Dmol\n",
        "pymol_color_list = [\"#33ff33\",\"#00ffff\",\"#ff33cc\",\"#ffff00\",\"#ff9999\",\"#e5e5e5\",\"#7f7fff\",\"#ff7f00\",\n",
        "                    \"#7fff7f\",\"#199999\",\"#ff007f\",\"#ffdd5e\",\"#8c3f99\",\"#b2b2b2\",\"#007fff\",\"#c4b200\",\n",
        "                    \"#8cb266\",\"#00bfbf\",\"#b27f7f\",\"#fcd1a5\",\"#ff7f7f\",\"#ffbfdd\",\"#7fffff\",\"#ffff7f\",\n",
        "                    \"#00ff7f\",\"#337fcc\",\"#d8337f\",\"#bfff3f\",\"#ff7fff\",\"#d8d8ff\",\"#3fffbf\",\"#b78c4c\",\n",
        "                    \"#339933\",\"#66b2b2\",\"#ba8c84\",\"#84bf00\",\"#b24c66\",\"#7f7f7f\",\"#3f3fa5\",\"#a5512b\"]\n",
        "\n",
        "def show_pdb(pdb_str, show_sidechains=False, show_mainchains=False,\n",
        "             color=\"pLDDT\", chains=None, vmin=50, vmax=90,\n",
        "             size=(800,480), hbondCutoff=4.0,\n",
        "             Ls=None,\n",
        "             animate=False):\n",
        "\n",
        "  if chains is None:\n",
        "    chains = 1 if Ls is None else len(Ls)\n",
        "  view = py3Dmol.view(js='https://3dmol.org/build/3Dmol.js', width=size[0], height=size[1])\n",
        "  if animate:\n",
        "    view.addModelsAsFrames(pdb_str,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "  else:\n",
        "    view.addModel(pdb_str,'pdb',{'hbondCutoff':hbondCutoff})\n",
        "  if color == \"pLDDT\":\n",
        "    view.setStyle({'cartoon': {'colorscheme': {'prop':'b','gradient': 'roygb','min':vmin,'max':vmax}}})\n",
        "  elif color == \"rainbow\":\n",
        "    view.setStyle({'cartoon': {'color':'spectrum'}})\n",
        "  elif color == \"chain\":\n",
        "    for n,chain,color in zip(range(chains),alphabet_list,pymol_color_list):\n",
        "       view.setStyle({'chain':chain},{'cartoon': {'color':color}})\n",
        "  if show_sidechains:\n",
        "    BB = ['C','O','N']\n",
        "    view.addStyle({'and':[{'resn':[\"GLY\",\"PRO\"],'invert':True},{'atom':BB,'invert':True}]},\n",
        "                  {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"GLY\"},{'atom':'CA'}]},\n",
        "                  {'sphere':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "    view.addStyle({'and':[{'resn':\"PRO\"},{'atom':['C','O'],'invert':True}]},\n",
        "                  {'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "  if show_mainchains:\n",
        "    BB = ['C','O','N','CA']\n",
        "    view.addStyle({'atom':BB},{'stick':{'colorscheme':f\"WhiteCarbon\",'radius':0.3}})\n",
        "  view.zoomTo()\n",
        "  if animate: view.animate()\n",
        "  return view\n",
        "\n",
        "color = \"confidence\" #@param [\"confidence\", \"rainbow\", \"chain\"]\n",
        "if color == \"confidence\": color = \"pLDDT\"\n",
        "show_sidechains = False #@param {type:\"boolean\"}\n",
        "show_mainchains = False #@param {type:\"boolean\"}\n",
        "show_pdb(pdb_str, color=color,\n",
        "         show_sidechains=show_sidechains,\n",
        "         show_mainchains=show_mainchains,\n",
        "         Ls=lengths).show()"
      ],
      "metadata": {
        "id": "JM5ciSmeTZKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot confidence (optional)\n",
        "\n",
        "dpi = 100 #@param {type:\"integer\"}\n",
        "\n",
        "def plot_ticks(Ls):\n",
        "  Ln = sum(Ls)\n",
        "  L_prev = 0\n",
        "  for L_i in Ls[:-1]:\n",
        "    L = L_prev + L_i\n",
        "    L_prev += L_i\n",
        "    plt.plot([0,Ln],[L,L],color=\"black\")\n",
        "    plt.plot([L,L],[0,Ln],color=\"black\")\n",
        "  ticks = np.cumsum([0]+Ls)\n",
        "  ticks = (ticks[1:] + ticks[:-1])/2\n",
        "  plt.yticks(ticks,alphabet_list[:len(ticks)])\n",
        "\n",
        "def plot_confidence(O, Ls=None, dpi=100):\n",
        "  if \"lm_contacts\" in O:\n",
        "    plt.figure(figsize=(20,4), dpi=dpi)\n",
        "    plt.subplot(1,4,1)\n",
        "  else:\n",
        "    plt.figure(figsize=(15,4), dpi=dpi)\n",
        "    plt.subplot(1,3,1)\n",
        "\n",
        "  plt.title('Predicted lDDT')\n",
        "  plt.plot(O[\"plddt\"])\n",
        "  if Ls is not None:\n",
        "    L_prev = 0\n",
        "    for L_i in Ls[:-1]:\n",
        "      L = L_prev + L_i\n",
        "      L_prev += L_i\n",
        "      plt.plot([L,L],[0,100],color=\"black\")\n",
        "  plt.xlim(0,O[\"plddt\"].shape[0])\n",
        "  plt.ylim(0,100)\n",
        "  plt.ylabel('plDDT')\n",
        "  plt.xlabel('position')\n",
        "  plt.subplot(1,4 if \"lm_contacts\" in O else 3,2)\n",
        "\n",
        "  plt.title('Predicted Aligned Error')\n",
        "  Ln = O[\"pae\"].shape[0]\n",
        "  plt.imshow(O[\"pae\"],cmap=\"bwr\",vmin=0,vmax=30,extent=(0, Ln, Ln, 0))\n",
        "  if Ls is not None and len(Ls) > 1: plot_ticks(Ls)\n",
        "  plt.colorbar()\n",
        "  plt.xlabel('Scored residue')\n",
        "  plt.ylabel('Aligned residue')\n",
        "\n",
        "  if \"lm_contacts\" in O:\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.title(\"contacts from LM\")\n",
        "    plt.imshow(O[\"lm_contacts\"],cmap=\"Greys\",vmin=0,vmax=1,extent=(0, Ln, Ln, 0))\n",
        "    if Ls is not None and len(Ls) > 1: plot_ticks(Ls)\n",
        "    plt.subplot(1,4,4)\n",
        "  else:\n",
        "    plt.subplot(1,3,3)\n",
        "  plt.title(\"contacts from Structure Module\")\n",
        "  plt.imshow(O[\"sm_contacts\"],cmap=\"Greys\",vmin=0,vmax=1,extent=(0, Ln, Ln, 0))\n",
        "  if Ls is not None and len(Ls) > 1: plot_ticks(Ls)\n",
        "  return plt\n",
        "\n",
        "plot_confidence(O, Ls=lengths, dpi=dpi)\n",
        "plt.savefig(f'{prefix}.png',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HGFBl0QYYQpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download predictions\n",
        "from google.colab import files\n",
        "os.system(f\"zip {ID}.zip {ID}/*\")\n",
        "files.download(f'{ID}.zip')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hkMp_ZwRYfAQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}